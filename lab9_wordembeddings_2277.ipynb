{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzN4btPKjFuxNqU6b6grsP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radha2006krishna/NLP/blob/main/lab9_wordembeddings_2277.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A90LsWGiPQVM",
        "outputId": "38316b44-22ca-4bc8-f491-be38a8271d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gensim is used to load and work with pre-trained word embedding models\n",
        "# It provides Word2Vec, GloVe, FastText implementations\n",
        "import gensim\n",
        "\n",
        "# KeyedVectors is specifically used to load pre-trained word embeddings\n",
        "# without loading the full training model\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# numpy is used for numerical operations on vectors\n",
        "# Word embeddings are stored as numerical arrays\n",
        "import numpy as np\n",
        "\n",
        "# sklearn.metrics.pairwise is used to calculate similarity between vectors\n",
        "# cosine_similarity helps measure semantic similarity between words\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# matplotlib is used to visualize word embeddings in 2D space\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KQ0hEIZrQFtE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load pre-trained Word2Vec model (may take time on first download)\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Print vocabulary size\n",
        "print(\"Vocabulary Size:\", len(model.key_to_index))\n",
        "\n",
        "# Display vector for a sample word\n",
        "word = \"king\"\n",
        "vector = model[word]\n",
        "\n",
        "print(\"\\nWord:\", word)\n",
        "print(\"Vector length:\", len(vector))\n",
        "print(\"First 10 values of the vector:\\n\", vector[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INEDb8-9QPtA",
        "outputId": "9c9c9569-01b7-41f2-f5ef-a8f786bc928e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Vocabulary Size: 3000000\n",
            "\n",
            "Word: king\n",
            "Vector length: 300\n",
            "First 10 values of the vector:\n",
            " [ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
            "  0.11181641 -0.19824219  0.05126953  0.36328125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load GloVe embeddings (100-dimensional)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Print vocabulary size\n",
        "print(\"Vocabulary Size:\", len(model.key_to_index))\n",
        "\n",
        "# Display vector for a sample word\n",
        "word = \"king\"\n",
        "vector = model[word]\n",
        "\n",
        "print(\"\\nWord:\", word)\n",
        "print(\"Vector length:\", len(vector))\n",
        "print(\"First 10 values of the vector:\\n\", vector[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UH4YdcuRZRU",
        "outputId": "528ccbfe-1d65-4f24-d4b9-5fef2f75f4b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Vocabulary Size: 400000\n",
            "\n",
            "Word: king\n",
            "Vector length: 100\n",
            "First 10 values of the vector:\n",
            " [-0.32307 -0.87616  0.21977  0.25268  0.22976  0.7388  -0.37954 -0.35307\n",
            " -0.84369 -1.1113 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe model (100D)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Define word pairs\n",
        "word_pairs = [\n",
        "    (\"doctor\", \"nurse\"),\n",
        "    (\"cat\", \"dog\"),\n",
        "    (\"car\", \"bus\"),\n",
        "    (\"king\", \"queen\"),\n",
        "    (\"man\", \"woman\"),\n",
        "    (\"teacher\", \"student\"),\n",
        "    (\"apple\", \"banana\"),\n",
        "    (\"computer\", \"keyboard\"),\n",
        "    (\"sun\", \"moon\"),\n",
        "    (\"river\", \"water\")\n",
        "]\n",
        "\n",
        "print(\"Word Similarity Scores:\\n\")\n",
        "\n",
        "for w1, w2 in word_pairs:\n",
        "    similarity = model.similarity(w1, w2)\n",
        "    print(f\"{w1} - {w2} : {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNJ_2xs_RyUL",
        "outputId": "ed6fb241-e76e-4c58-c2aa-a11f5468ef53"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Similarity Scores:\n",
            "\n",
            "doctor - nurse : 0.7522\n",
            "cat - dog : 0.8798\n",
            "car - bus : 0.7373\n",
            "king - queen : 0.7508\n",
            "man - woman : 0.8323\n",
            "teacher - student : 0.8083\n",
            "apple - banana : 0.5054\n",
            "computer - keyboard : 0.5418\n",
            "sun - moon : 0.6138\n",
            "river - water : 0.6306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe embeddings (100D)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Choose at least 5 words\n",
        "chosen_words = [\"king\", \"university\", \"doctor\", \"car\", \"music\"]\n",
        "\n",
        "for word in chosen_words:\n",
        "    print(f\"\\nTop similar words for '{word}':\\n\")\n",
        "\n",
        "    similar_words = model.most_similar(word, topn=5)\n",
        "\n",
        "    for similar_word, score in similar_words:\n",
        "        print(f\"{similar_word} : {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33HXLi_vR1Xd",
        "outputId": "74eb2e6f-8e8b-4b5a-e326-4abe0a5facc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top similar words for 'king':\n",
            "\n",
            "prince : 0.7682\n",
            "queen : 0.7508\n",
            "son : 0.7021\n",
            "brother : 0.6986\n",
            "monarch : 0.6978\n",
            "\n",
            "Top similar words for 'university':\n",
            "\n",
            "college : 0.8294\n",
            "harvard : 0.8156\n",
            "yale : 0.8114\n",
            "professor : 0.8104\n",
            "graduate : 0.7993\n",
            "\n",
            "Top similar words for 'doctor':\n",
            "\n",
            "physician : 0.7673\n",
            "nurse : 0.7522\n",
            "dr. : 0.7175\n",
            "doctors : 0.7081\n",
            "patient : 0.7074\n",
            "\n",
            "Top similar words for 'car':\n",
            "\n",
            "vehicle : 0.8631\n",
            "truck : 0.8598\n",
            "cars : 0.8372\n",
            "driver : 0.8186\n",
            "driving : 0.7813\n",
            "\n",
            "Top similar words for 'music':\n",
            "\n",
            "musical : 0.8128\n",
            "songs : 0.7978\n",
            "dance : 0.7897\n",
            "pop : 0.7863\n",
            "recording : 0.7651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained Word2Vec (better for analogies)\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Analogy 1\n",
        "result1 = model.most_similar(\n",
        "    positive=[\"king\", \"woman\"],\n",
        "    negative=[\"man\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 2\n",
        "result2 = model.most_similar(\n",
        "    positive=[\"paris\", \"india\"],\n",
        "    negative=[\"france\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 3\n",
        "result3 = model.most_similar(\n",
        "    positive=[\"teacher\", \"hospital\"],\n",
        "    negative=[\"school\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "print(\"\\nking - man + woman = ?\")\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nparis - france + india = ?\")\n",
        "print(result2)\n",
        "\n",
        "print(\"\\nteacher - school + hospital = ?\")\n",
        "print(result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQwcTYUpR52f",
        "outputId": "7a59997e-e5ad-41d9-f415-6fe4889e5254"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "king - man + woman = ?\n",
            "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581)]\n",
            "\n",
            "paris - france + india = ?\n",
            "[('chennai', 0.5442505478858948), ('delhi', 0.5149926543235779), ('mumbai', 0.5024341344833374), ('hyderabad', 0.49932485818862915), ('gujarat', 0.48732805252075195)]\n",
            "\n",
            "teacher - school + hospital = ?\n",
            "[('Hospital', 0.6331106424331665), ('nurse', 0.6280134320259094), ('hopsital', 0.6217317581176758), ('intensive_care', 0.5683753490447998), ('Hosptial', 0.5647749304771423)]\n"
          ]
        }
      ]
    }
  ]
}