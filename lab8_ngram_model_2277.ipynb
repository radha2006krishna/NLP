{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpdZnfZoGATjqwLzw04XB7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radha2006krishna/NLP/blob/main/lab8_ngram_model_2277.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uni Gram Counts**"
      ],
      "metadata": {
        "id": "VajWPkjobz7Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us7gKAJuO8dg",
        "outputId": "cab66ca5-7972-451e-cbe5-076951773944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "the: 8\n",
            "to: 3\n",
            "a: 3\n",
            "reduce: 2\n",
            "team: 2\n",
            "increased: 2\n",
            "regional: 1\n",
            "transit: 1\n",
            "authority: 1\n",
            "implemented: 1\n",
            "predictive: 1\n",
            "maintenance: 1\n",
            "bus: 1\n",
            "downtime.: 1\n",
            "clinical: 1\n",
            "trial: 1\n",
            "reported: 1\n",
            "improved: 1\n",
            "glycemic: 1\n",
            "control: 1\n",
            "among: 1\n",
            "participants: 1\n",
            "on: 1\n",
            "new: 1\n",
            "diet.: 1\n",
            "cybersecurity: 1\n",
            "discovered: 1\n",
            "critical: 1\n",
            "vulnerability: 1\n",
            "in: 1\n",
            "authentication: 1\n",
            "system.: 1\n",
            "satellite: 1\n",
            "data: 1\n",
            "indicated: 1\n",
            "accelerated: 1\n",
            "glacier: 1\n",
            "melt: 1\n",
            "due: 1\n",
            "rising: 1\n",
            "temperatures.: 1\n",
            "marketing: 1\n",
            "conversions: 1\n",
            "through: 1\n",
            "multivariate: 1\n",
            "a/b: 1\n",
            "testing.: 1\n",
            "blockchain: 1\n",
            "ledger: 1\n",
            "enhanced: 1\n",
            "transparency: 1\n",
            "across: 1\n",
            "supply: 1\n",
            "chain.: 1\n",
            "city: 1\n",
            "council: 1\n",
            "approved: 1\n",
            "zoning: 1\n",
            "changes: 1\n",
            "for: 1\n",
            "mixed-use: 1\n",
            "development.: 1\n",
            "machine: 1\n",
            "learning: 1\n",
            "models: 1\n",
            "predicted: 1\n",
            "customer: 1\n",
            "churn: 1\n",
            "more: 1\n",
            "accurately: 1\n",
            "than: 1\n",
            "legacy: 1\n",
            "methods.: 1\n",
            "legal: 1\n",
            "advisors: 1\n",
            "revised: 1\n",
            "indemnification: 1\n",
            "clause: 1\n",
            "liability: 1\n",
            "risk.: 1\n",
            "renewable: 1\n",
            "energy: 1\n",
            "adoption: 1\n",
            "required: 1\n",
            "advanced: 1\n",
            "grid: 1\n",
            "load-balancing: 1\n",
            "strategies.: 1\n",
            "Vocabulary Size= 88\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "D1= \"The regional transit authority implemented predictive maintenance to reduce bus downtime.\"\n",
        "\n",
        "D2= \"A clinical trial reported improved glycemic control among participants on the new diet.\"\n",
        "\n",
        "D3= \"The cybersecurity team discovered a critical vulnerability in the authentication system.\"\n",
        "\n",
        "D4= \"Satellite data indicated accelerated glacier melt due to rising temperatures.\"\n",
        "\n",
        "D5= \"The marketing team increased conversions through multivariate A/B testing.\"\n",
        "\n",
        "D6= \"A blockchain ledger enhanced transparency across the supply chain.\"\n",
        "\n",
        "D7= \"The city council approved zoning changes for mixed-use development.\"\n",
        "\n",
        "D8= \"Machine learning models predicted customer churn more accurately than legacy methods.\"\n",
        "\n",
        "D9= \"Legal advisors revised the indemnification clause to reduce liability risk.\"\n",
        "\n",
        "D10= \"Increased renewable energy adoption required advanced grid load-balancing strategies.\"\n",
        "\n",
        "D1_content =\"The regional transit authority implemented predictive maintenance to reduce bus downtime.\"\n",
        "D2_content =\"A clinical trial reported improved glycemic control among participants on the new diet.\"\n",
        "D3_content =\"The cybersecurity team discovered a critical vulnerability in the authentication system.\"\n",
        "D4_content =\"Satellite data indicated accelerated glacier melt due to rising temperatures.\"\n",
        "D5_content =\"The marketing team increased conversions through multivariate A/B testing.\"\n",
        "D6_content =\"A blockchain ledger enhanced transparency across the supply chain.\"\n",
        "D7_content =\"The city council approved zoning changes for mixed-use development.\"\n",
        "D8_content =\"Machine learning models predicted customer churn more accurately than legacy methods.\"\n",
        "D9_content =\"Legal advisors revised the indemnification clause to reduce liability risk.\"\n",
        "D10_content =\"Increased renewable energy adoption required advanced grid load-balancing strategies.\"\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content} {D5_content} {D6_content} {D7_content} {D8_content} {D9_content} {D10_content}\"\n",
        "words = combined_text.lower().split()\n",
        "unigram_counts = collections.Counter(words)\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "Ypuih43gcCiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content} {D5_content} {D6_content} {D7_content} {D8_content} {D9_content} {D10_content}\"\n",
        "words = combined_text.lower().split()\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3c_TveCSc4e",
        "outputId": "86994e62-caaf-4846-fd92-c997931cc52b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "to reduce: 2\n",
            "the regional: 1\n",
            "regional transit: 1\n",
            "transit authority: 1\n",
            "authority implemented: 1\n",
            "implemented predictive: 1\n",
            "predictive maintenance: 1\n",
            "maintenance to: 1\n",
            "reduce bus: 1\n",
            "bus downtime.: 1\n",
            "downtime. a: 1\n",
            "a clinical: 1\n",
            "clinical trial: 1\n",
            "trial reported: 1\n",
            "reported improved: 1\n",
            "improved glycemic: 1\n",
            "glycemic control: 1\n",
            "control among: 1\n",
            "among participants: 1\n",
            "participants on: 1\n",
            "on the: 1\n",
            "the new: 1\n",
            "new diet.: 1\n",
            "diet. the: 1\n",
            "the cybersecurity: 1\n",
            "cybersecurity team: 1\n",
            "team discovered: 1\n",
            "discovered a: 1\n",
            "a critical: 1\n",
            "critical vulnerability: 1\n",
            "vulnerability in: 1\n",
            "in the: 1\n",
            "the authentication: 1\n",
            "authentication system.: 1\n",
            "system. satellite: 1\n",
            "satellite data: 1\n",
            "data indicated: 1\n",
            "indicated accelerated: 1\n",
            "accelerated glacier: 1\n",
            "glacier melt: 1\n",
            "melt due: 1\n",
            "due to: 1\n",
            "to rising: 1\n",
            "rising temperatures.: 1\n",
            "temperatures. the: 1\n",
            "the marketing: 1\n",
            "marketing team: 1\n",
            "team increased: 1\n",
            "increased conversions: 1\n",
            "conversions through: 1\n",
            "through multivariate: 1\n",
            "multivariate a/b: 1\n",
            "a/b testing.: 1\n",
            "testing. a: 1\n",
            "a blockchain: 1\n",
            "blockchain ledger: 1\n",
            "ledger enhanced: 1\n",
            "enhanced transparency: 1\n",
            "transparency across: 1\n",
            "across the: 1\n",
            "the supply: 1\n",
            "supply chain.: 1\n",
            "chain. the: 1\n",
            "the city: 1\n",
            "city council: 1\n",
            "council approved: 1\n",
            "approved zoning: 1\n",
            "zoning changes: 1\n",
            "changes for: 1\n",
            "for mixed-use: 1\n",
            "mixed-use development.: 1\n",
            "development. machine: 1\n",
            "machine learning: 1\n",
            "learning models: 1\n",
            "models predicted: 1\n",
            "predicted customer: 1\n",
            "customer churn: 1\n",
            "churn more: 1\n",
            "more accurately: 1\n",
            "accurately than: 1\n",
            "than legacy: 1\n",
            "legacy methods.: 1\n",
            "methods. legal: 1\n",
            "legal advisors: 1\n",
            "advisors revised: 1\n",
            "revised the: 1\n",
            "the indemnification: 1\n",
            "indemnification clause: 1\n",
            "clause to: 1\n",
            "reduce liability: 1\n",
            "liability risk.: 1\n",
            "risk. increased: 1\n",
            "increased renewable: 1\n",
            "renewable energy: 1\n",
            "energy adoption: 1\n",
            "adoption required: 1\n",
            "required advanced: 1\n",
            "advanced grid: 1\n",
            "grid load-balancing: 1\n",
            "load-balancing strategies.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "rbMkjhp7cHap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "combined_text = f\"{D1_content} {D2_content} {D3_content} {D4_content} {D5_content} {D6_content} {D7_content} {D8_content} {D9_content} {D10_content}\"\n",
        "words = combined_text.lower().split()\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9phobSfSicg",
        "outputId": "7474247c-cf1d-42bd-d45f-0b7e43555401"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "the regional transit: 1\n",
            "regional transit authority: 1\n",
            "transit authority implemented: 1\n",
            "authority implemented predictive: 1\n",
            "implemented predictive maintenance: 1\n",
            "predictive maintenance to: 1\n",
            "maintenance to reduce: 1\n",
            "to reduce bus: 1\n",
            "reduce bus downtime.: 1\n",
            "bus downtime. a: 1\n",
            "downtime. a clinical: 1\n",
            "a clinical trial: 1\n",
            "clinical trial reported: 1\n",
            "trial reported improved: 1\n",
            "reported improved glycemic: 1\n",
            "improved glycemic control: 1\n",
            "glycemic control among: 1\n",
            "control among participants: 1\n",
            "among participants on: 1\n",
            "participants on the: 1\n",
            "on the new: 1\n",
            "the new diet.: 1\n",
            "new diet. the: 1\n",
            "diet. the cybersecurity: 1\n",
            "the cybersecurity team: 1\n",
            "cybersecurity team discovered: 1\n",
            "team discovered a: 1\n",
            "discovered a critical: 1\n",
            "a critical vulnerability: 1\n",
            "critical vulnerability in: 1\n",
            "vulnerability in the: 1\n",
            "in the authentication: 1\n",
            "the authentication system.: 1\n",
            "authentication system. satellite: 1\n",
            "system. satellite data: 1\n",
            "satellite data indicated: 1\n",
            "data indicated accelerated: 1\n",
            "indicated accelerated glacier: 1\n",
            "accelerated glacier melt: 1\n",
            "glacier melt due: 1\n",
            "melt due to: 1\n",
            "due to rising: 1\n",
            "to rising temperatures.: 1\n",
            "rising temperatures. the: 1\n",
            "temperatures. the marketing: 1\n",
            "the marketing team: 1\n",
            "marketing team increased: 1\n",
            "team increased conversions: 1\n",
            "increased conversions through: 1\n",
            "conversions through multivariate: 1\n",
            "through multivariate a/b: 1\n",
            "multivariate a/b testing.: 1\n",
            "a/b testing. a: 1\n",
            "testing. a blockchain: 1\n",
            "a blockchain ledger: 1\n",
            "blockchain ledger enhanced: 1\n",
            "ledger enhanced transparency: 1\n",
            "enhanced transparency across: 1\n",
            "transparency across the: 1\n",
            "across the supply: 1\n",
            "the supply chain.: 1\n",
            "supply chain. the: 1\n",
            "chain. the city: 1\n",
            "the city council: 1\n",
            "city council approved: 1\n",
            "council approved zoning: 1\n",
            "approved zoning changes: 1\n",
            "zoning changes for: 1\n",
            "changes for mixed-use: 1\n",
            "for mixed-use development.: 1\n",
            "mixed-use development. machine: 1\n",
            "development. machine learning: 1\n",
            "machine learning models: 1\n",
            "learning models predicted: 1\n",
            "models predicted customer: 1\n",
            "predicted customer churn: 1\n",
            "customer churn more: 1\n",
            "churn more accurately: 1\n",
            "more accurately than: 1\n",
            "accurately than legacy: 1\n",
            "than legacy methods.: 1\n",
            "legacy methods. legal: 1\n",
            "methods. legal advisors: 1\n",
            "legal advisors revised: 1\n",
            "advisors revised the: 1\n",
            "revised the indemnification: 1\n",
            "the indemnification clause: 1\n",
            "indemnification clause to: 1\n",
            "clause to reduce: 1\n",
            "to reduce liability: 1\n",
            "reduce liability risk.: 1\n",
            "liability risk. increased: 1\n",
            "risk. increased renewable: 1\n",
            "increased renewable energy: 1\n",
            "renewable energy adoption: 1\n",
            "energy adoption required: 1\n",
            "adoption required advanced: 1\n",
            "required advanced grid: 1\n",
            "advanced grid load-balancing: 1\n",
            "grid load-balancing strategies.: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts**"
      ],
      "metadata": {
        "id": "KY2sC5QlcMmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "    return predicted_word\n",
        "sequence1 = \"The regional\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "sequence2 = \"in the\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "sequence3 = \"accurately than\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "sequence4 = \"to rising\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thnVyF5sUpZT",
        "outputId": "bf1ca404-df57-4928-9413-72df2c0f871b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  transit is  1.0\n",
            "Given sequence: 'The regional', predicted next word: 'transit'\n",
            "probability of  regional is  0.125\n",
            "probability of  new is  0.125\n",
            "probability of  cybersecurity is  0.125\n",
            "probability of  authentication is  0.125\n",
            "probability of  marketing is  0.125\n",
            "probability of  supply is  0.125\n",
            "probability of  city is  0.125\n",
            "probability of  indemnification is  0.125\n",
            "Given sequence: 'in the', predicted next word: 'regional'\n",
            "probability of  legacy is  1.0\n",
            "Given sequence: 'accurately than', predicted next word: 'legacy'\n",
            "probability of  temperatures. is  1.0\n",
            "Given sequence: 'to rising', predicted next word: 'temperatures.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Bi-Gram Model**"
      ],
      "metadata": {
        "id": "ZdUYU9eScRPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j36sjeMX5df",
        "outputId": "4c459dd9-0b02-4bbb-c655-da41e06fe4d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textRISING\n",
            "probability of  temperatures. is  1.0\n",
            "Given sequence: 'RISING', predicted next word: 'temperatures.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts**"
      ],
      "metadata": {
        "id": "HfaHCe8fcV5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"a blockchain ledger\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"to reduce liability\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SC0w5G5YCqb",
        "outputId": "612b137d-1319-4767-c3f5-5c363fd8a0ba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  enhanced is  1.0\n",
            "Given sequence: 'a blockchain ledger', predicted next word: 'enhanced'\n",
            "probability of  risk. is  1.0\n",
            "Given sequence: 'to reduce liability', predicted next word: 'risk.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Tri-Gram Model**"
      ],
      "metadata": {
        "id": "N5VKnt3cYt2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve4HP3WqYveS",
        "outputId": "dbee91fb-be62-4651-8697-8628adc6af13"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textto\n",
            "Given sequence: 'to', predicted next word: 'Sequence must contain at least two words for trigram prediction.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening**"
      ],
      "metadata": {
        "id": "T1blEvAZY4JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"satellite data\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"a blockchain\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"machine learning\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"advanced grid\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXRiMXCuZA1D",
        "outputId": "0eecb414-48a8-4be5-adbc-c29e4a536581"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of indicated is  0.02247191011235955\n",
            "Given sequence: 'satellite data', predicted next word: 'indicated'\n",
            "probability of ledger is  0.02247191011235955\n",
            "Given sequence: 'a blockchain', predicted next word: 'ledger'\n",
            "probability of models is  0.02247191011235955\n",
            "Given sequence: 'machine learning', predicted next word: 'models'\n",
            "probability of load-balancing is  0.02247191011235955\n",
            "Given sequence: 'advanced grid', predicted next word: 'load-balancing'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "cCwOtsgDZnzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTQSYL6BZtQD",
        "outputId": "010206eb-25be-4e45-db61-1886c28e0ee8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texta blockchain\n",
            "probability of ledger is  0.02247191011235955\n",
            "Given sequence: 'a blockchain', predicted next word: 'ledger'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts based on laplace smoothening**"
      ],
      "metadata": {
        "id": "i0wYDMAnZ0TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"melt due to\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"the regional transit\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LW_S5BNZ10k",
        "outputId": "2c1f282e-ba54-4077-f098-5247619c3773"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  rising is  0.02247191011235955\n",
            "Given sequence: 'melt due to', predicted next word: 'rising'\n",
            "probability of  authority is  0.02247191011235955\n",
            "Given sequence: 'the regional transit', predicted next word: 'authority'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Laplace Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "CqW5O8w5aLo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sYy41D2aNAm",
        "outputId": "ebf0c0dd-f3bc-402f-8eec-d6d1ccffee42"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textmelt due to\n",
            "probability of  rising is  0.02247191011235955\n",
            "Given sequence: 'melt due to', predicted next word: 'rising'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "RaVn-_fnaYeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"authority implemented\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"clinical trial\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"in the\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"the supply\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbbu6bfeacBn",
        "outputId": "4b266982-ed45-425b-de45-3e0ed848e5a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of predictive is  0.03333333333333333\n",
            "Given sequence: 'authority implemented', predicted next word: 'predictive'\n",
            "probability of reported is  0.03333333333333333\n",
            "Given sequence: 'clinical trial', predicted next word: 'reported'\n",
            "probability of regional is  0.028846153846153848\n",
            "probability of new is  0.028846153846153848\n",
            "probability of cybersecurity is  0.028846153846153848\n",
            "probability of authentication is  0.028846153846153848\n",
            "probability of marketing is  0.028846153846153848\n",
            "probability of supply is  0.028846153846153848\n",
            "probability of city is  0.028846153846153848\n",
            "probability of indemnification is  0.028846153846153848\n",
            "Given sequence: 'in the', predicted next word: 'regional'\n",
            "probability of chain. is  0.03333333333333333\n",
            "Given sequence: 'the supply', predicted next word: 'chain.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Bi-Gram Model**"
      ],
      "metadata": {
        "id": "Bx7qfzc6bHOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvlE4zoObMsW",
        "outputId": "5f3938fb-d518-46fe-a935-22c79b1752d1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textin the\n",
            "probability of regional is  0.028846153846153848\n",
            "probability of new is  0.028846153846153848\n",
            "probability of cybersecurity is  0.028846153846153848\n",
            "probability of authentication is  0.028846153846153848\n",
            "probability of marketing is  0.028846153846153848\n",
            "probability of supply is  0.028846153846153848\n",
            "probability of city is  0.028846153846153848\n",
            "probability of indemnification is  0.028846153846153848\n",
            "Given sequence: 'in the', predicted next word: 'regional'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening**"
      ],
      "metadata": {
        "id": "ODPA14CcbRpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"across the supply\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"indemnification clause to\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08dRmXKwbWa2",
        "outputId": "bfaa3dea-d3b6-4654-d162-f7f67c06353b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  chain. is  0.03333333333333333\n",
            "Given sequence: 'across the supply', predicted next word: 'chain.'\n",
            "probability of  reduce is  0.03333333333333333\n",
            "Given sequence: 'indemnification clause to', predicted next word: 'reduce'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deployment of Add-K Smoothening based Tri-Gram Model**"
      ],
      "metadata": {
        "id": "xg_tCAiDbsCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZDfKo0xbtmf",
        "outputId": "017e050d-2f51-46f8-ace3-c3138f38e4ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textacross the supply\n",
            "probability of  chain. is  0.03333333333333333\n",
            "Given sequence: 'across the supply', predicted next word: 'chain.'\n"
          ]
        }
      ]
    }
  ]
}